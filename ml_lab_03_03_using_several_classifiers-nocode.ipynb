{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using several classifiers and tuning parameters - Parameters grid\n",
    "[From official `scikit-learn` documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html)\n",
    "\n",
    "Adapted by Claudio Sartori\n",
    "\n",
    "Example of usage of the ***model selection*** features of `scikit-learn` and comparison of several classification methods.\n",
    "1. import a sample dataset \n",
    "1. split the dataset into two parts: train and test\n",
    "    - the *train* part will be used for training and validation (i.e. for *development*)\n",
    "    - the *test* part will be used for test (i.e. for *evaluation*)\n",
    "    - the fraction of test data will be _ts_ (a value of your choice between 0.2 and 0.5)\n",
    "1. the function `GridSearchCV` iterates a cross validation experiment to train and test a model with different combinations of paramater values\n",
    "    - for each parameter we set a list of values to test, the function will generate all the combinations\n",
    "    - we choose a *score function* which will be used for the optimization\n",
    "        - e.g. `accuracy_score`, `precision_score`, `cohen_kappa_score`, `f1_score`, see this [page](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) for reference\n",
    "    - the output is a dictionary containing \n",
    "        - the set of parameters which maximize the score \n",
    "        - the test scores\n",
    "1. prepare the parameters for the grid\n",
    "    - it is a list of dictionaries\n",
    "1. set the parameters by cross validation and the *score functions* to choose from\n",
    "1. Loop on scores and, for each score, loop on the model labels (see details below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
      "@author: scikit-learn.org and Claudio Sartori\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "@author: scikit-learn.org and Claudio Sartori\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # uncomment this line to suppress warnings\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(__doc__) # print information included in the triple quotes at the beginning\n",
    "\n",
    "# Loading a standard dataset\n",
    "#dataset = datasets.load_digits()\n",
    "# dataset = datasets.fetch_olivetti_faces() # 40 classes!\n",
    "# dataset = datasets.fetch_covtype()        # 581012 examples\t 54 features \n",
    "# dataset = datasets.load_iris()    # 150 examples -- 4 features -- 3 classes\n",
    "dataset = datasets.load_wine()      # 178 examples -- 13 features -- 3 classes\n",
    "# dataset = datasets.load_breast_cancer() # binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def print_results(model):\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    for mean, std, params_tuple in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params_tuple))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    Ytrue, Ypred = Ytest, model.predict(Xtest)\n",
    "    print(classification_report(Ytrue, Ypred))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prepare the environment\n",
    "The `dataset` module contains, among others, a few sample datasets.\n",
    "\n",
    "See this [page](http://scikit-learn.org/stable/datasets/index.html) for reference\n",
    "\n",
    "Prepare the data and the target in X and y. Set `ts`. Set the random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    178 examples -- 13 features -- 3 classes\n"
     ]
    }
   ],
   "source": [
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "print(\"{:7} examples -- {} features -- {} classes\".format(X.shape[0],X.shape[1], np.unique(Y).shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into the train and test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training samples dimension (133, 13)\n",
      " training labels dimension (133,)\n",
      " testing samples dimension (45, 13)\n",
      " testing labels dimension (45,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y)\n",
    "print('\\n training samples dimension {}\\n training labels dimension {}\\n testing samples dimension {}\\n testing labels dimension {}'.format(Xtrain.shape,Ytrain.shape,Xtest.shape,Ytest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below is intended to ease the remainder of the exercise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_lbls = [\n",
    "             'dt', \n",
    "             'nb', \n",
    "#              'lp', \n",
    "#              'svc', \n",
    "#              'knn',\n",
    "            ]\n",
    "\n",
    "# Set the parameters to be explored by the grid for each classifier\n",
    "tuned_param_dt = [{'max_depth': list(range(1,20))}]\n",
    "tuned_param_nb = [{'var_smoothing': [10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-07, 1e-8, 1e-9, 1e-10]}]\n",
    "tuned_param_lp = [{'early_stopping': [True]}]\n",
    "tuned_param_svc = [{'kernel': ['rbf'], \n",
    "                    'gamma': [1e-3, 1e-4],\n",
    "                    'C': [1, 10, 100, 1000],\n",
    "                    },\n",
    "                    {'kernel': ['linear'],\n",
    "                     'C': [1, 10, 100, 1000],                     \n",
    "                    },\n",
    "                   ]\n",
    "tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "# set the models to be fitted specifying name, estimator and parameter structure\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(), \n",
    "           'param': tuned_param_dt,\n",
    "          },\n",
    "    'nb': {'name': 'Gaussian Naive Bayes',\n",
    "           'estimator': GaussianNB(),\n",
    "           'param': tuned_param_nb\n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(),\n",
    "           'param': tuned_param_lp,\n",
    "          },\n",
    "    'svc':{'name': 'Support Vector      ',\n",
    "           'estimator': SVC(), \n",
    "           'param': tuned_param_svc\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': tuned_param_knn\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "# scores to be explored\n",
    "scores = [\n",
    "          'precision', \n",
    "#           'recall',\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Try GridSearchCV with a DecisionTreeClassifier\n",
    "Use `GridSearchCV` to get the best `max_depth` value for a `DecisionTreeClassifier` evaluating accuracy:\n",
    "- Define the parameters to be tested and the range of values for each one\n",
    "- Get a `GridSearchCV` instance for a `DecisionTreeClassifier`\n",
    "- Fit the instance to the training data\n",
    "\n",
    "**It's ok to get results that are different than the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=DecisionTreeClassifier(),\n             param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n                                        13, 14, 15, 16, 17, 18, 19]}])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTree = DecisionTreeClassifier();\n",
    "\n",
    "clf_dt = GridSearchCV(DTree, tuned_param_dt);\n",
    "\n",
    "clf_dt.fit(Xtrain,Ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The function below groups all the outputs\n",
    "Write a `print_results` function that takes a fitted model and uses its attributes to inspect the results of the search with the parameter grid.\n",
    "\n",
    "The attributes are:<br>\n",
    "`model.best_params_`<br>\n",
    "`model.cv_results_['mean_test_score']`<br>`\n",
    "model.cv_results_['std_test_score']`<br>\n",
    "`model.cv_results_['params']`\n",
    "\n",
    "The report is generated by the `classification_report` function imported from `sklearn.metrics`, which takes as argument the true test labels and the predicted test labels.\n",
    "\n",
    "The +/- in the results is obtained doubling the `std_test_score`. Mean and standard test scores are computed considering the various results on the cross-validation chunks.\n",
    "\n",
    "The function will be used to print the results for each set of parameters in the last part of the exercise.\n",
    "\n",
    "Use `print_results` to show the result of the tuning above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_depth': 15}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.60797721, 0.82649573, 0.90968661, 0.9022792 , 0.9022792 ,\n       0.90940171, 0.87977208, 0.89430199, 0.87948718, 0.90940171,\n       0.9017094 , 0.9022792 , 0.87948718, 0.85726496, 0.92450142,\n       0.90911681, 0.89487179, 0.90940171, 0.92450142])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.cv_results_['mean_test_score']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.08209579, 0.0783367 , 0.06038004, 0.07259984, 0.06020503,\n       0.06958569, 0.07197102, 0.07323877, 0.07283424, 0.06958569,\n       0.07779395, 0.08952218, 0.08001388, 0.09224084, 0.05300983,\n       0.07059781, 0.06358065, 0.05653387, 0.05300983])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.cv_results_['std_test_score']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'max_depth': 1},\n {'max_depth': 2},\n {'max_depth': 3},\n {'max_depth': 4},\n {'max_depth': 5},\n {'max_depth': 6},\n {'max_depth': 7},\n {'max_depth': 8},\n {'max_depth': 9},\n {'max_depth': 10},\n {'max_depth': 11},\n {'max_depth': 12},\n {'max_depth': 13},\n {'max_depth': 14},\n {'max_depth': 15},\n {'max_depth': 16},\n {'max_depth': 17},\n {'max_depth': 18},\n {'max_depth': 19}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.cv_results_['params']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'max_depth': 15}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.608 (+/-0.164) for {'max_depth': 1}\n",
      "0.826 (+/-0.157) for {'max_depth': 2}\n",
      "0.910 (+/-0.121) for {'max_depth': 3}\n",
      "0.902 (+/-0.145) for {'max_depth': 4}\n",
      "0.902 (+/-0.120) for {'max_depth': 5}\n",
      "0.909 (+/-0.139) for {'max_depth': 6}\n",
      "0.880 (+/-0.144) for {'max_depth': 7}\n",
      "0.894 (+/-0.146) for {'max_depth': 8}\n",
      "0.879 (+/-0.146) for {'max_depth': 9}\n",
      "0.909 (+/-0.139) for {'max_depth': 10}\n",
      "0.902 (+/-0.156) for {'max_depth': 11}\n",
      "0.902 (+/-0.179) for {'max_depth': 12}\n",
      "0.879 (+/-0.160) for {'max_depth': 13}\n",
      "0.857 (+/-0.184) for {'max_depth': 14}\n",
      "0.925 (+/-0.106) for {'max_depth': 15}\n",
      "0.909 (+/-0.141) for {'max_depth': 16}\n",
      "0.895 (+/-0.127) for {'max_depth': 17}\n",
      "0.909 (+/-0.113) for {'max_depth': 18}\n",
      "0.925 (+/-0.106) for {'max_depth': 19}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       1.00      0.76      0.87        17\n",
      "           2       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.92      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(clf_dt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loop on scores and, for each score, loop on the model labels\n",
    "- iterate varying the score function\n",
    "    1. iterate varying the classification model among Decision Tree, Naive Bayes, Linear Perceptron, Support Vector\n",
    "        - activate the *grid search*\n",
    "            1. the resulting model will be the best one according to the current score function\n",
    "        - print the best parameter set and the results for each set of parameters using the above defined function\n",
    "        - print the classification report\n",
    "        - store the `.best score_` in a dictionary for a final report\n",
    "    1. print the final report for the current *score funtion*\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'var_smoothing': 1e-05}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.533 (+/-0.119) for {'var_smoothing': 10}\n",
      "0.654 (+/-0.150) for {'var_smoothing': 1}\n",
      "0.691 (+/-0.115) for {'var_smoothing': 0.1}\n",
      "0.699 (+/-0.132) for {'var_smoothing': 0.01}\n",
      "0.768 (+/-0.148) for {'var_smoothing': 0.001}\n",
      "0.895 (+/-0.143) for {'var_smoothing': 0.0001}\n",
      "0.962 (+/-0.049) for {'var_smoothing': 1e-05}\n",
      "0.962 (+/-0.096) for {'var_smoothing': 1e-06}\n",
      "0.962 (+/-0.096) for {'var_smoothing': 1e-07}\n",
      "0.962 (+/-0.096) for {'var_smoothing': 1e-08}\n",
      "0.962 (+/-0.096) for {'var_smoothing': 1e-09}\n",
      "0.962 (+/-0.096) for {'var_smoothing': 1e-10}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "GNB = GaussianNB();\n",
    "\n",
    "clf_nb = GridSearchCV(GNB, tuned_param_nb);\n",
    "\n",
    "clf_nb.fit(Xtrain,Ytrain)\n",
    "\n",
    "print_results(clf_nb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'early_stopping': True}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.578 (+/-0.231) for {'early_stopping': True}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        15\n",
      "           1       0.57      0.94      0.71        17\n",
      "           2       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.46      0.62      0.53        45\n",
      "weighted avg       0.49      0.67      0.56        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Perceptron\n",
    "LP = Perceptron();\n",
    "\n",
    "clf_lp = GridSearchCV(LP, tuned_param_lp);\n",
    "\n",
    "clf_lp.fit(Xtrain,Ytrain)\n",
    "\n",
    "print_results(clf_lp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.624 (+/-0.227) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.662 (+/-0.125) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.676 (+/-0.221) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.722 (+/-0.184) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.699 (+/-0.207) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.797 (+/-0.209) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.699 (+/-0.207) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.827 (+/-0.174) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.947 (+/-0.060) for {'C': 1, 'kernel': 'linear'}\n",
      "0.947 (+/-0.060) for {'C': 10, 'kernel': 'linear'}\n",
      "0.947 (+/-0.060) for {'C': 100, 'kernel': 'linear'}\n",
      "0.947 (+/-0.060) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        15\n",
      "           1       1.00      0.82      0.90        17\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector\n",
    "SVM = SVC();\n",
    "\n",
    "clf_svm = GridSearchCV(SVM, tuned_param_svc);\n",
    "\n",
    "clf_svm.fit(Xtrain,Ytrain)\n",
    "\n",
    "print_results(clf_svm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_neighbors': 9}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.653 (+/-0.266) for {'n_neighbors': 1}\n",
      "0.631 (+/-0.180) for {'n_neighbors': 2}\n",
      "0.646 (+/-0.256) for {'n_neighbors': 3}\n",
      "0.661 (+/-0.230) for {'n_neighbors': 4}\n",
      "0.639 (+/-0.161) for {'n_neighbors': 5}\n",
      "0.616 (+/-0.174) for {'n_neighbors': 6}\n",
      "0.639 (+/-0.138) for {'n_neighbors': 7}\n",
      "0.647 (+/-0.139) for {'n_neighbors': 8}\n",
      "0.693 (+/-0.101) for {'n_neighbors': 9}\n",
      "0.655 (+/-0.178) for {'n_neighbors': 10}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        15\n",
      "           1       0.86      0.71      0.77        17\n",
      "           2       0.69      0.69      0.69        13\n",
      "\n",
      "    accuracy                           0.80        45\n",
      "   macro avg       0.79      0.80      0.79        45\n",
      "weighted avg       0.80      0.80      0.80        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector\n",
    "KNN = KNeighborsClassifier();\n",
    "\n",
    "clf_knn = GridSearchCV(KNN, tuned_param_knn);\n",
    "\n",
    "clf_knn.fit(Xtrain,Ytrain)\n",
    "\n",
    "print_results(clf_knn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt': 0.9245014245014247, 'nb': 0.9621082621082622, 'lp': 0.5783475783475783, 'svc': 0.9472934472934474, 'knn': 0.6925925925925925}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = {\n",
    "    'dt': clf_dt.best_score_,\n",
    "    'nb': clf_nb.best_score_,\n",
    "    'lp': clf_lp.best_score_,\n",
    "    'svc': clf_svm.best_score_,\n",
    "    'knn': clf_knn.best_score_\n",
    "}\n",
    "names = list(scores.keys())\n",
    "values = list(scores.values())\n",
    "print(scores)\n",
    "plt.bar(range(len(scores)), values, tick_label=names)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "pycharm-7de540f2",
   "language": "python",
   "display_name": "PyCharm (Lab on topic 03-03 - Usage of several classifiers-20211115)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}